import streamlit as st
import requests
import pandas as pd
from urllib.parse import unquote
from datetime import datetime, timedelta
import io
import re
import pytz

# --- [1] ë¶€ì¥ë‹˜ ì •ì˜ˆ ì»¤ìŠ¤í…€ ì„¤ì • ---
SERVICE_KEY = unquote('9ada16f8e5bc00e68aa27ceaa5a0c2ae3d4a5e0ceefd9fdca653b03da27eebf0')
HEADERS = {'User-Agent': 'Mozilla/5.0'}

# ìˆ˜ì§‘ ëŒ€ìƒ í‚¤ì›Œë“œ (v28.5 ê¸°ì¤€)
KEYWORDS = ["íê¸°ë¬¼", "ìš´ë°˜", "íëª©ì¬", "íí•©ì„±ìˆ˜ì§€", "ì‹ë¬¼ì„±", "ë‚™ì—½", "ì„ëª©", "ê°€ì—°ì„±"]

def clean_date_strict(val):
    if not val or val == "-": return "-"
    s = re.sub(r'[^0-9]', '', str(val).split('.')[0])
    if len(s) >= 8: return f"{s[:4]}-{s[4:6]}-{s[6:8]}"
    return val

# --- [2] ëŒ€ì‹œë³´ë“œ ë ˆì´ì•„ì›ƒ ---
st.set_page_config(page_title="THE RADAR v9000", layout="wide")
st.title("ğŸ“¡ THE RADAR v9000.0 (ì§€ì—­/ì—…ì¢… ë¬´ì¡°ê±´ ìˆ˜ì§‘)")

if st.button("ğŸš€ 2ë‹¨ê³„ ìƒì„¸ ìˆ˜ìƒ‰ ì‹œì‘ (í•„í„° ì—†ìŒ)", type="primary"):
    final_list = []
    KST = pytz.timezone('Asia/Seoul')
    now = datetime.now(KST)
    
    # ìµœê·¼ 4ì¼ì¹˜ ë°ì´í„° ìˆ˜ì§‘
    s_date = (now - timedelta(days=4)).strftime("%Y%m%d0000")
    e_date = now.strftime("%Y%m%d2359")
    
    status_st = st.empty()
    url_base = 'https://apis.data.go.kr/1230000/ad/BidPublicInfoService/'

    # --- 1ë‹¨ê³„: í‚¤ì›Œë“œë¡œ ê³µê³  ëª©ë¡ ì„œì¹˜ ---
    all_raw = []
    for kw in KEYWORDS:
        status_st.info(f"ğŸ” 1ë‹¨ê³„: í‚¤ì›Œë“œ '{kw}' ê²€ìƒ‰ ì¤‘...")
        params = {'serviceKey': SERVICE_KEY, 'numOfRows': '100', 'type': 'json', 'inqryDiv': '1', 'inqryBgnDt': s_date, 'inqryEndDt': e_date, 'bidNtceNm': kw}
        try:
            res = requests.get(url_base + 'getBidPblancListInfoServcPPSSrch', params=params, timeout=10).json()
            items = res.get('response', {}).get('body', {}).get('items', [])
            if items:
                for it in ([items] if isinstance(items, dict) else items):
                    it['searchKeyword'] = kw
                    all_raw.append(it)
        except: pass

    if all_raw:
        # ê³µê³ ë²ˆí˜¸ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±°
        df_bids = pd.DataFrame(all_raw).drop_duplicates(subset=['bidNtceNo'])
        
        # --- 2ë‹¨ê³„: ê³µê³ ë²ˆí˜¸ ëŒ€ì…í•˜ì—¬ ì´ë¯¸ì§€ ì† ìƒì„¸ ì •ë³´(ì§€ì—­/ì—…ì¢…) ë¬´ì¡°ê±´ ì¶”ì¶œ ---
        for i, row in df_bids.iterrows():
            b_no = row['bidNtceNo']
            b_ord = str(row.get('bidNtceOrd', '00')).zfill(2)
            status_st.warning(f"âš™ï¸ 2ë‹¨ê³„: ê³µê³ ë²ˆí˜¸({b_no}) ìƒì„¸ ë°ì´í„° ì¶”ì¶œ ì¤‘... ({i+1}/{len(df_bids)})")

            # ì´ë¯¸ì§€ í•­ëª© ì´ˆê¸°ê°’ ì„¤ì •
            reg_val = "í™•ì¸ë¶ˆê°€"
            lic_code = "í™•ì¸ë¶ˆê°€"
            lic_name = "í™•ì¸ë¶ˆê°€"
            
            try:
                # [ë¶€ì¥ë‹˜ ì´ë¯¸ì§€ í•­ëª©] ìš©ì—­ê³µê³  ìƒì„¸ì¡°íšŒ API í˜¸ì¶œ
                det_res = requests.get(url_base + 'getBidPblancListInfoServcDetail', 
                                     params={'serviceKey': SERVICE_KEY, 'type': 'json', 'bidNtceNo': b_no, 'bidNtceOrd': b_ord}, timeout=5).json()
                det_item = det_res.get('response', {}).get('body', {}).get('item', {})

                if det_item:
                    # ğŸ¯ ì´ë¯¸ì§€ ì† prtcptLmtRgnNm (ì°¸ê°€ì œí•œì§€ì—­ëª…) ì¶”ì¶œ
                    reg_val = det_item.get('prtcptLmtRgnNm', 'ì „êµ­(ì œí•œì—†ìŒ)')
                    
                    # ğŸ¯ ì´ë¯¸ì§€ ì† indstrytyCd (ì—…ì¢…ì½”ë“œ) ë° indstrytyNm (ì—…ì¢…ëª…) ì¶”ì¶œ
                    lic_code = det_item.get('indstrytyCd', '-')
                    lic_name = det_item.get('indstrytyNm', '-')
            except:
                pass

            # í•„í„° ì—†ì´ ëª¨ë“  ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            final_list.append({
                'í‚¤ì›Œë“œ': row['searchKeyword'],
                'ê³µê³ ë²ˆí˜¸': b_no,
                'ê³µê³ ëª…': row['bidNtceNm'],
                'ì°¸ê°€ì œí•œì§€ì—­ëª…(prtcptLmtRgnNm)': reg_val,
                'ì—…ì¢…ì½”ë“œ(indstrytyCd)': lic_code,
                'ì—…ì¢…ëª…(indstrytyNm)': lic_name,
                'ìˆ˜ìš”ê¸°ê´€': row['dminsttNm'],
                'ë°°ì •ì˜ˆì‚°': int(pd.to_numeric(row.get('asignBdgtAmt', 0), errors='coerce') or 0),
                'ë§ˆê°ì¼ì‹œ': clean_date_strict(row.get('bidClseDt')),
                'ìƒì„¸URL': row.get('bidNtceDtlUrl', '')
            })

        status_st.empty()
        if final_list:
            df_final = pd.DataFrame(final_list)
            # ë§ˆê°ì¼ ìˆœ ì •ë ¬
            df_final = df_final.sort_values(by=['ë§ˆê°ì¼ì‹œ'])
            
            st.success(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ! ì´ {len(df_final)}ê±´ì˜ ì§€ì—­ ë° ì—…ì¢… ì •ë³´ë¥¼ í™•ë³´í–ˆìŠµë‹ˆë‹¤.")
            st.dataframe(df_final.style.format({'ë°°ì •ì˜ˆì‚°': '{:,}ì›'}), use_container_width=True)
            
            # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                df_final.to_excel(writer, index=False)
            st.download_button(label="ğŸ“¥ ìˆ˜ì§‘ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ", data=output.getvalue(), file_name=f"G2B_FULL_DATA_{now.strftime('%m%d')}.xlsx")
        else:
            st.warning("âš ï¸ ê²€ìƒ‰ëœ ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")
